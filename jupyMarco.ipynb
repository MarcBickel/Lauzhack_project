{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report, confusion_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['suspicious', 'non-suspicious']\n",
    "\n",
    "#These are the functions I will use for result visualisation\n",
    "def plot_confusion_matrix(y_test,y_predicted,labels):\n",
    "    cm = confusion_matrix(y_test, y_predicted.round())\n",
    "\n",
    "    figsize = (10,7)\n",
    "    df_cm = pd.DataFrame(\n",
    "        cm, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def evaluate_classifier(pipeline, x_test, y_test):\n",
    "\n",
    "    y_predicted = pipeline.predict(x_test)\n",
    "\n",
    "    report = classification_report(y_test, np.round(y_predicted))\n",
    "    print(report)\n",
    "    plot_confusion_matrix(y_test, y_predicted, class_names)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv', index_col='customer')\n",
    "test_data = pd.read_csv('data/test.csv', index_col='customer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dummies = pd.get_dummies(train_data, columns=['category', 'is_pep', 'nationality'])\n",
    "test_dummies = pd.get_dummies(test_data, columns=['category', 'is_pep', 'nationality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_dummies.drop(['suspicious'], axis=1)\n",
    "y_train = pd.DataFrame(train_dummies['suspicious'])\n",
    "x_test = test_dummies.copy()\n",
    "x_test['nationality_117'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turnover</th>\n",
       "      <th>transaction_count</th>\n",
       "      <th>io_ratio</th>\n",
       "      <th>age</th>\n",
       "      <th>inactive_days_average</th>\n",
       "      <th>inactive_days_max</th>\n",
       "      <th>n_of_accounts</th>\n",
       "      <th>distinct_counterparties</th>\n",
       "      <th>channel_risk</th>\n",
       "      <th>atm_withdrawal</th>\n",
       "      <th>...</th>\n",
       "      <th>nationality_66</th>\n",
       "      <th>nationality_94</th>\n",
       "      <th>nationality_113</th>\n",
       "      <th>nationality_117</th>\n",
       "      <th>nationality_123</th>\n",
       "      <th>nationality_134</th>\n",
       "      <th>nationality_141</th>\n",
       "      <th>nationality_172</th>\n",
       "      <th>nationality_176</th>\n",
       "      <th>nationality_191</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90000000</th>\n",
       "      <td>734958.58</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>79.0</td>\n",
       "      <td>24.63</td>\n",
       "      <td>124.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.128703</td>\n",
       "      <td>215959.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           turnover  transaction_count  io_ratio   age  inactive_days_average  \\\n",
       "customer                                                                        \n",
       "90000000  734958.58                7.0  0.142857  79.0                  24.63   \n",
       "\n",
       "          inactive_days_max  n_of_accounts  distinct_counterparties  \\\n",
       "customer                                                              \n",
       "90000000              124.0              3                      6.0   \n",
       "\n",
       "          channel_risk  atm_withdrawal       ...         nationality_66  \\\n",
       "customer                                     ...                          \n",
       "90000000      0.128703       215959.85       ...                      0   \n",
       "\n",
       "          nationality_94  nationality_113  nationality_117  nationality_123  \\\n",
       "customer                                                                      \n",
       "90000000               0                0                0                0   \n",
       "\n",
       "          nationality_134  nationality_141  nationality_172  nationality_176  \\\n",
       "customer                                                                       \n",
       "90000000                1                0                0                0   \n",
       "\n",
       "          nationality_191  \n",
       "customer                   \n",
       "90000000                0  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('normalizer', Normalizer()), \n",
    "    ('random_forest', RandomForestClassifier(n_estimators=1000, criterion='entropy',  max_depth=10, random_state=0, n_jobs=-1, \n",
    "                                            class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classifier(pipeline, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummies_suspicious = train_dummies[train_dummies['suspicious'] == 1]\n",
    "x_train_suspicious = train_dummies_suspicious.drop(['suspicious'], axis=1)\n",
    "y_train_suspicious = pd.DataFrame(train_dummies_suspicious['suspicious'])\n",
    "\n",
    "train_dummies_non_suspicious = train_dummies[train_dummies['suspicious'] == 0]\n",
    "x_train_non_suspicious = train_dummies_non_suspicious.drop(['suspicious'], axis=1)\n",
    "y_train_non_suspicious = pd.DataFrame(train_dummies_non_suspicious['suspicious'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(x_train_non_suspicious.shape[0], x_train_suspicious.shape[0])\n",
    "x_train_non_suspicious[indexes_selected_non_suspicious]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    indexes_selected_non_suspicious = np.random.choice(x_train_non_suspicious.shape[0], x_train_suspicious.shape[0])\n",
    "    x_selected_non_suspicious = x_train_non_suspicious.values[indexes_selected_non_suspicious]\n",
    "    y_selected_non_suspicious = y_train_non_suspicious.values[indexes_selected_non_suspicious]\n",
    "    x_total = np.vstack((x_selected_non_suspicious, x_train_suspicious))\n",
    "    y_total = np.vstack((y_selected_non_suspicious, y_train_suspicious))\n",
    "    evaluate_classifier(pipeline, x_total, y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_classes=2, class_sep=1.5, weights=[0.9, 0.1],\n",
    "    n_informative=3, n_redundant=1, flip_y=0,\n",
    "    n_features=20, n_clusters_per_class=1,\n",
    "    n_samples=100, random_state=10\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df['target'] = y\n",
    "df.target.value_counts().plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    indices = np.random.choice(x_train.shape[0], int(x_train.shape[0]*0.1))\n",
    "    ids = x_train.index[indices]\n",
    "\n",
    "    x_train_train = x_train.values[indices]\n",
    "    x_train_validation = x_train.drop(ids)\n",
    "    y_train_train = y_train.values[indices]\n",
    "    y_train_validation = y_train.drop(ids)\n",
    "\n",
    "    rus = RandomUnderSampler(return_indices=True)\n",
    "    X_rus, y_rus, id_rus = rus.fit_sample(x_train_train, y_train_train)\n",
    "\n",
    "    pipeline.fit(X_rus, y_rus)\n",
    "    accs.append(evaluate_classifier(pipeline, x_train_validation, y_train_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = pipeline.predict_proba(x_test)\n",
    "\n",
    "data_set_with_label = x_test.copy(deep=True)\n",
    "\n",
    "data_set_with_label['label'] = predicted_labels[:,1]\n",
    "\n",
    "data_set_with_label = data_set_with_label.sort_values(by='label',ascending=False)\n",
    "\n",
    "aaa = data_set_with_label.head(1000)\n",
    "\n",
    "aaa.index.to_frame().to_csv(\"res.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "batch_size, D_in, H, D_out = 64, x_train.shape[1], 100, 1\n",
    "#la première ligne qui contient le numéro de frame ne nous intéresse pas dans le NN\n",
    "\n",
    "#Define the model sequentially\n",
    "m = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, H),\n",
    "    torch.nn.ReLU(), \n",
    "    torch.nn.Linear(H, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "lambda_ = 1e-4\n",
    "epochs = 1000\n",
    "loss = torch.nn.BCELoss()\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_NNmodel_batch(model, xs, ys, learning_rate, loss_fn, number_of_epochs, batch_size):\n",
    "    #to run on GPU\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in tqdm_notebook(range(number_of_epochs), desc='Epoch', leave=False):\n",
    "        \n",
    "        #get number of random indexes equal to batch_size\n",
    "        indexes_batch = np.random.choice(xs.shape[0], batch_size, replace=False)\n",
    "        #get the rows that correspond to these \n",
    "        x_selected = xs[indexes_batch]\n",
    "\n",
    "        #give directly the matrix as input to the model\n",
    "        x = torch.tensor(x_selected, dtype = torch.float, device=device)         \n",
    "        \n",
    "        y_temp = ys[indexes_batch]\n",
    "        y = torch.tensor(y_temp, dtype=torch.float, device = device)\n",
    "        \n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # Compute and print loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        #print('Epoch: ', epoch, ' Column: ', i, ' Loss: ', loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1000, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_NNmodel_batch(m, x_train.values, y_train.values, lambda_, loss, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(model, validation):\n",
    "    predicted_labels = pipeline.predict_proba(x_test)\n",
    "\n",
    "    data_set_with_label = x_test.copy(deep=True)\n",
    "\n",
    "    data_set_with_label['label'] = predicted_labels[:,1]\n",
    "\n",
    "    data_set_with_label = data_set_with_label.sort_values(by='label',ascending=False)\n",
    "    aaa = data_set_with_label.head(1000)\n",
    "    aaa.index.to_frame().to_csv(\"res.csv\",index=False)\n",
    "    \n",
    "    y = model(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "y_pred = m(torch.tensor(x_test.values, dtype=torch.float, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-49539824.  ],\n",
       "       [ -2124255.2 ],\n",
       "       [  -504120.97],\n",
       "       ...,\n",
       "       [-35322550.  ],\n",
       "       [ -2409645.  ],\n",
       "       [ -7345604.5 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.cpu().detach().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
